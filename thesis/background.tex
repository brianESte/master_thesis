%! TeX root = thesis.tex
\chapter{Background}\label{background}
(? Does there need to be any text to introduce the background chapter?, ie, a paragraph here)

\section{Geometric Curvature}
For segmenting a 3D mesh via Watershed Segmentation each vertex requires a singular / combined measure of curvature.
The various forms and types of curvature examined throughout this project are presented in the following sections.

\subsection{Principal Curvatures}
All combined measures of curvature are based, either in theory or in actuality, on the principal curvatures.
The principal curvatures at a given point on a surface are simply the maximum and minimum curvature\cite{DDGAppIntro_17_smooth_k}.
The principal curvatures at the top of a hill-like surface are illustrated in figure \ref{fig:principal_k}.
Determining principal curvatures for a continuous surface is unambiguous.
The principal curvatures of a surface $S$ at point $p$ are defined by the 2nd fundamental form\cite{DiffGeo_curves_surfaces, Basic_diff_geo_of_surfaces, DDGAppIntro_17_smooth_k}:
\begin{equation}
	II(X,Y) := \langle dN(X), df(Y)\rangle,
\end{equation}
and can be found as the eigenvalues of
\begin{equation}\label{2nd_fundamental_tensor}
	\begin{bmatrix}
		II(X_1, X_2) & II(X_1, X_2) \\
		II(X_2, X_1) & II(X_2, X_2)
	\end{bmatrix}.
\end{equation}
Similarly, the principal directions are the eigenvectors of \ref{2nd_fundamental_tensor}.

\begin{figure}
	\centering
	% \includegraphics[width=0.7\textwidth]{../resources/minimal_surface_curvature_planes-en.svg.png}
	\includegraphics[width=0.7\textwidth]{../resources/principal_curvatures.png}
	% \includesvg[width=0.9\textwidth]{../resources/Minimal_surface_curvature_planes-en.svg}
	\caption{
Principal curvatures shown on an ellipsoidally round surface\cite{Digital_geom_proc_w_disc_ext_calc}.
$X_1$ and $X_2$ show the principal directions.
The curvature of a curve at a given point is the inverse of the radius of said curve.
The cutaway views show this as an osculated circle in each projection of the surface.
	}
	\label{fig:principal_k}
\end{figure}

There are however various ways of approximating the principal curvatures on a discrete mesh\cite{EstCurvOnTriMesh, DiscDiffGeoOpsTriMani}.
A basic approach is to calculate the mean and Gaussian curvatures, and derive the principal curvatures from them\cite{DDGAppIntro_19_discrete_k_2, Gauss_mean_k_notes}.
Given the mean curvature $H$ and Gaussian curvature $K$ (see \ref{sec:mean_k} and \ref{sec:gauss_k}), the principal curvatures can be calculated from \ref{eq:mean_k} and \ref{eq:gauss_k}.
\begin{align}
	\kappa_1 &= H - \sqrt{H^2 - K} \\
	\kappa_2 &= H + \sqrt{H^2 - K}
\end{align}
Although theoretically impossible, discretization errors can cause $H^2$ to be less than $K$, resulting in ``imaginary'' curvature.
This tends to occur on planar mesh regions, thus a minimum of 0 can be set for $H^2 - K$, because the root term would have been near 0 regardless, but it does highlight a flaw in this measure of curvature.

Taubin calculated the principal curvatures directly by estimating the tensor of curvature\cite{TaubinTensor}.
This has the benefit of direct calculation, but has been shown to be succeptible to noise in the mesh\cite{Comp_k_notes}.
Thiesel et al. calculate the curvature tensor per triangular face in the mesh, based on the face's corner normals\cite{Norm_based_k_tensor_est}.
Rusinkiewicz took a slightly different approach, calculating the curvature tensor for each mesh face via the differences between corner normals\cite{SRTensor}.
From there he computes the per vertex curvature tensor as a weighted sum over the curvature tensors of the vertex's adjoining triangles via coordinate system transformations.
Gatzke and Grimm examine a variety of other curvature estimation methods\cite{EstCurvOnTriMesh}, most of which were not considered for this work.

\subsection{Mean Curvature}\label{sec:mean_k}
Mean curvature is, as the name implies, the mean of the principal curvatures\cite{DDGAppIntro_19_discrete_k_2}:
\begin{equation}\label{eq:mean_k}
	H = \frac{\kappa_1 + \kappa_2}{2}
\end{equation}
Mean curvature can be approximated on a discrete mesh via sum of dihedral edge angle length products:
\begin{equation}\label{eq:dihedral_angle}
	H_i := \frac{1}{2}\sum_{j \in E}l_{ij} \phi_{ij}
\end{equation}
where $H_i$ is the mean curvature at vertex $i$, $j$ is a vertex in the ring of $i$, $l_{ij}$ is the length of the edge from $i$ to $j$, and $\phi_{ij}$ is the dihedral angle between the faces adjacent to edge $ij$.
See \ref{sfig:dihedral_angle} for a graphical depiction.

Alternatively, the mean curvature normal $\Delta f$ can be calculated via the discrete Laplace-Beltrami operator\cite{DDGAppIntro_18_discrete_k_1}:
\begin{equation}\label{eq:lap_beltrami_op}
	(\Delta f)_i := \frac{1}{2}\sum_{j \in E}(\cot \alpha_{ij} + \cot \beta_{ij})(p_j - p_i),
\end{equation}
and the absolute mean curvature can be calculated as half of the magnitude thereof:
\begin{equation}
	|H_i| = \frac{\|(\Delta f)_i \|}{2}.
\end{equation}
In equation \ref{eq:lap_beltrami_op} above $p_j$ is a vertex in the ring of vertex $p_i$ which indicates the current edge, $\alpha_{ij}$ and $\beta_{ij}$ are the angles opposite the current edge (see \ref{sfig:mesh_neighborhood}).

\begin{figure}[t]
	\centering
	\begin{subfigure}{0.45\textwidth}
		\centering
\begin{tikzpicture}[
	vertex/.style={circle, radius=2pt,fill, inner sep=2pt,outer sep=0pt},
	hidden/.style={inner sep=0, outer sep=0}]
	\node [vertex,label=180:i] (node_i) at (-0.4,2.2) {};
	\node [vertex,label=215:j] (node_j) at (0.4,-2.2) {};
	\node [hidden] (node_l) at (-2.3,-0.8) {};
	\node [hidden] (node_r) at (1.7,0.5) {};
	\draw (node_i) -- (node_j) -- (node_r) -- (node_i) -- (node_l) -- (node_j);
	\draw [dashed,gray!60] (node_l) -- (node_r);
	% try to draw curved arrow
	\draw [-Stealth,thick] (20:4mm) arc [start angle=20, delta angle=-180, x radius=5mm, y radius=3mm];
		% node [pos=0.8, label={250:$\phi_{ij}$}] {};
	\node [] at (-0.3, -0.6) {$\phi_{ij}$};
	\draw [|-|, thick] ($(node_i.east)+(0.1,0.05)$) -- ($(node_j.east)+(0.1,0.05)$)
		node [pos=0.65,label={0:$l_{ij}$}] {};
\end{tikzpicture}
		\caption{Dihedral angle of adjacent mesh faces. Inspired by \cite{DDGAppIntro_19_discrete_k_2}.}
		\label{sfig:dihedral_angle}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\textwidth}
		\centering
\begin{tikzpicture}[
	scale=1.1,
	vertex/.style={circle, radius=2pt,fill, inner sep=2pt,outer sep=0pt}]
	% based on image in slide 26/44 in DDG-DiscreteCurvatureI.pdf
	\newdimen\hexR
	\hexR=2cm
	\newlength\arcR
	\arcR=4mm
	\node[vertex,label=south west:i] (0, 0) {};
	\draw [thick] (330: \hexR) \foreach \x in {30,90,...,330} { -- (\x:\hexR) };
	\foreach \x in {30,90,...,330} {
		\draw (0, 0) -- (\x:\hexR) node[vertex]{};
	}
	% Vertex j
	\node [label=270:j] at (270:\hexR) {};
	\node [label=330:k] at (330:\hexR) {};
	% Inner main angle
	\draw (270:\arcR) arc [radius=\arcR, start angle=270, end angle=330]
		node [pos=0.5, label={[xshift=-3.5mm, yshift=1mm]300:$\Theta{ijk}$}] {};
	% Inner angles
	\draw (210:\hexR) +(330:\arcR) arc [radius=\arcR, start angle=-30, end angle=30]
		node [pos=0.5, label={[xshift=-2.2mm]0:$\alpha_{ij}$}] {};
	\draw (330:\hexR) +(150:\arcR) arc [radius=\arcR, start angle=150, end angle=210]
		node [pos=0.5, label={[xshift=2.5mm]180:$\beta_{ij}$}] {};
\end{tikzpicture}
		\caption{\raggedright The triangular mesh neighborhood around vertex $i$.}
		\label{sfig:mesh_neighborhood}
	\end{subfigure}
\caption{
(a) depicts two adjacent triangular faces connected by edge $ij$, with angle the dihedral angle between them denoted $\phi_{ij}$ and the length of edge $ij$ as $l_{ij}$.
(b) depicts the neighborhood of faces around vertex $i$ on some triangular mesh.
The angle between adjacent edges radiating from vertex $i$ is denoted $\Theta_{ijk}$.
The angles opposite edge $ij$ are indicated as $\alpha_{ij}$ and $\beta_{ij}$.
}
\end{figure}

\subsection{Gaussian Curvature}\label{sec:gauss_k}
Gaussian curvature\cite{TheoremaEgregium} is the product of the principal curvatures:

\begin{equation}\label{eq:gauss_k}
	K = \kappa_1 \cdot \kappa_2
\end{equation}

The discrete Gaussian curvature at a vertex is typically approximated as the ``angle defect'' divided by the vertex's area:
\begin{equation}
	K = \frac{2\pi - \sum \Theta_j}{A_i}
\end{equation}
where $\Theta_j$ is the angle between adjacent edges from the central vertex ($\Theta_{ijk}$ in \ref{sfig:mesh_neighborhood}), and $A_i$ is the vertex area.

Mean and Gaussian curvature are compared visually in figure \ref{fig:mean_gauss_k} from Pulla et al.
Note that the Gaussian curvature is approximately 0 over the entire surface, because the surface curves in only 1 direction, thus the 2nd principal curvature is ~0.
The colors shown in the mean curvature plot are effectively due entirely to the 1st principal curvature values.

\begin{figure}
	\centering
	% TODO: create a tikz picture to replace this image
	\includegraphics[width=0.9\textwidth]{../resources/gaussian_mean_k.png}
	\caption{Comparison of Gaussian (a) and mean (b) curvature\cite{Imp_k_estimation_for_WS}}
	\label{fig:mean_gauss_k} % NOTE: Label should be declared after caption
\end{figure}

\subsection{Root Mean Square Curvature}
Pulla et al. propsed using the root mean square curvature as the curvature estimate for use during watershed segmentation:
\begin{equation}
	\kappa_{rms} = \sqrt{\frac{\kappa_1^2 + \kappa_2^2}{2}}.
\end{equation}
They compared different measures of curvature for this purpose and found that it was approximately as good as absolute curvature:
\begin{equation}
	\kappa_{abs} = |\kappa_1| + |\kappa_2|,
\end{equation}
but cheaper to compute, because they computed $\kappa_{rms}$ from the mean and Gaussian curvatures using:
\begin{equation}
	\kappa_{rms} = \sqrt{4H^2 - 2K}.
\end{equation}
RMS curvature was used during developement prior to implementing the derivative of curvature.

\subsection{Derivative of Curvature}
Through testing it was determined that supplying the derivative of curvature instead of the curvature itself to watershed segmentation would better preserve the boundaries between semantic regions.
Rusinkiewicz proposes a method of taking the derivative of the curvature tensor\cite{SRTensor}.
Because watershed segmentation expects a single value rather than a tensor, the magnitude of the derivative of the curvature tensor was approximated as the sum of squares of said tensor.

\section{Surface Regression}
Part of the \textit{Surface Classification} step is to confirm the surface type estimation by performing the corresponding surface regression on the target surface and comparing the error value to a pre-defined threshold.

\subsection{Planar Regression}\label{sec:planar_regression}
A plane may be defined by a normal vector and a point on the plane.
% To perform planar regression on a set of 3D points principal component analysis is used to
Given a set of 3D points, principal component analysis (PCA) can be used to calculate the plane's normal vector as the PCA's least principal component.
% Given a set of 3D points, the least principal component from a PCA of the points is the regression plane's normal vector.
% That it, the direction that explains the least variance of the 3D points ... is the most significant for the normal vec?
The mean of the points is sufficient to produce the intersection point on the plane.
Calculating the error of such a regression is done by computing the distance from each point to the plane and calculating the root mean square of said distances like so:
\begin{equation}
	e_{RMSE} = \left(\frac{1}{N}\sum_{i}^{N}d_i^2 \right)^{\frac{1}{2}}.
\end{equation}
% The distance from a point $p_i$ to a plane described by point $p_P$ and normalized normal vector $\vec{n}$ may be calculated by transforming the point $p_i$ to the plane's coordinate system, with the origin at $p_P$ and which $\vec{n} = \vec{e_z}$.
The distance from a point $p_i$ to a plane described by point $p_P$ and normalized normal vector $\vec{n}$ may be calculated by transforming the target point to the plane's coordinate system, and taking the transformed point's $z$ coordinate as the distance.
% The distance from a point $p_i$ to a plane may be calculated by transforming the target point to the plane's coordinate system, with the origin at $p_P$ and which $\vec{n} = \vec{e_z}$:
\begin{equation}
	\prescript{P}{}p_i = \prescript{P}{}T_0 \prescript{0}{}p_i
\end{equation}
\begin{equation}
	d_i = \vec{e_z} \cdot \prescript{P}{}p_i
\end{equation}
where $\prescript{P}{}T_0$ is the homogeneous transformation matrix from global to planar coordinate systems.
Alternatively, if there is no other reason to compute the transformation matrix for the plane's local coordinate system, it is simpler to calculate the point-plane distance as the dot product of the plane normal with the vector $p_i - p_P$ as shown:
\begin{equation}
	d_i = \langle p_i - p_P, \vec{n}\rangle,
\end{equation}

\subsection{Cylindric Regression}
Cylinders in this context can be understood as an extruded conic section.
While there are methods of ascertaining (? better word?) a cylinder from a mere collection of 3D points\cite{PCL_cyl_regression}, the process employed here was simplified by exploiting the mesh's normals.
For a cylindric mesh of constant radius with vertex normals, the normals will all be perpendicular to the main axis.
Thus, the least principal component from a PCA performed on the mesh's normals will yield a vector along the main axis.
From here a coordinate system may be created such that the z axis is the cylinder's main axis.
The origin of the cylindric coordinate system is for cylindric, and thus conic regression, inconsequential, but is typically set initially to the mean point position of the mesh.
Next, the mesh vertices are projected onto the XY plane of the cylinder's coordinate system, so that the specific type of conic may be deduced.
The general equation of a conic is:
\begin{equation}\label{eq:gen_conic}
	Ax^2 + Bxy + Cy^2 + Dx + Ey + F = 0.
\end{equation}
% Treating this as the error function to be minimized via least squares
Fitting a given set of 3D points to this equation can be achieved via total least squares.
Rosin shows that it is useful to set $F = 1$\cite{Ellipse_least_squares}, both to normalize the equation, and to avoid the trivial solution
\begin{equation}
	A = B = C = D = E = F = 0.
\end{equation}
Once the coefficients have been obtained, the specific type of conic represented by the points may be discerned by the determinant
\begin{equation*}
	B^2 - 4AC.
\end{equation*}
The specific method and equations to check the validity of the conic regression depend on the type of conic.

\subsubsection{Elliptic Regression}\label{sec:elliptic_reg}
For $B^2 - 4AC < 0$ the set of points represent an ellipse.

Computing the distance from a given point to an ellipse or other conic shape is non-trivial and, at the time of writing, no exact algebraic solution was found.
In place of an exact distance function, the sum of squared residuals was used throughout most of the project's timeline.
For example, a point on a conic section should satisfy equation \ref{eq:gen_conic}, but for a point \textit{almost} on a conic section, the result will be non-zero:
\begin{equation}
	R(x,y) = Ax^2 + Bxy + Cy^2 + Dx + Ey + F \neq 0,
\end{equation}
where $R(x,y)$ is known as the residual. The error function then becomes:
\begin{equation}
	e = \sum_i \left(Ax_i^2 + Bx_i y_i + Cy_i^2 + Dx_i + Ey_i + F\right)^2.
\end{equation}
While easy to calculate, this value is unreliable as an indicator of whether or not the given surface is actually a conic surface.
During testing cases were encountered in which obviously non-cylindric surfaces yielded extremely low error values, resulting in false positives.
This realization fueled the need for a proper point-to-ellipse distance function.

Eberly\cite{GeoTools_pt_to_ellipse} shows that for an origin-centered axis-aligned ellipse described by major and minor diameters $a$ and $b$, and a target point $(x_p, y_p)$, the distance $t$ from the target point to the ellipse must satisfy the equation
\begin{equation}\label{eq:ellipse_dist}
	F(t) = \left(\frac{a x_p}{t + a^2}\right)^2 + \left(\frac{b y_p}{t + b^2}\right)^2 - 1 = 0.
\end{equation}
Eberly also compares 3 methods of solving equation \ref{eq:ellipse_dist} for $t$, concluding that the bisection method is the most robust.

\subsubsection{Parabolic and Hyperbolic Regression}
% TODO: return to this, improve it.?
The functionality to perform parabolic or hyperbolic regression was omitted from this work due to time constraints.
(? I could layout how to compute the distance and thus error for at least a parabola, but is it worth it if it is not implemented? it is safe to assume the vast majority of curves encountered will be circular, and if not circular then elliptic...)

\section{UV Mapping}
UV Mapping is the process of projecting a surface from 3D to 2D, effectively ``unwrapping'' the 3D surface.
(insert sentence about common usage in 3D modeling / graphics and textures)
The UV map for planar surfaces is trivial, as the 3D surface is already ``unwrapped''.

\subsection{Conic Surfaces}
General equation of a conic is:
\begin{equation}\label{eq:gen_conic}
	Ax^2 + Bxy + Cy^2 + Dx + Ey + F = 0
\end{equation}

\subsubsection{Elliptic Surface}
General equation:
\begin{equation}
	\frac{x^2}{a^2} + \frac{y^2}{b^2} = 1
\end{equation}
To obtain a vector perpendicular to a point on the ellipse, the derivative of said point is rotated 90 degrees.
The point, as a function of the angle $\theta$:
\begin{equation}
	(x,y) = (a\cos\theta, b\sin\theta)
\end{equation}
The derivative thereof:
\begin{equation}
	\frac{d}{d\theta}(x,y) = (-a\sin\theta, b\cos\theta)
\end{equation}
Rotated -90 degrees:
\begin{equation}
	\text{Rot}_{90}\frac{d}{d\theta}(x,y) = (b\cos\theta, a\sin\theta)
\end{equation}

\subsubsection{Parabolic Surface}
Parabolas are much simpler than and ellipses and hyperbolas, as can be seen by the following equations.
The parametric general equation of a parabola is:
\begin{equation}
	-\sin\theta x + \cos\theta y = \frac{1}{4f}(\cos\theta x + \sin\theta y - h)^2 + k
\end{equation}
To solve for the conic parameters of a parabola the general equation's quadratic term is expanded and like terms gathered:
\begin{multline*}
	-\sin\theta x + \cos\theta y = \frac{1}{4f}(\cos^2\theta x^2 + \cos\theta\sin\theta xy \\
	- h \cos\theta x + \cos\theta\sin\theta xy + \sin^2\theta y^2 - h\sin\theta y - h \cos\theta x - h \sin\theta y + h^2) + k
\end{multline*}
\begin{multline*}
	\frac{\cos^2\theta}{4f} x^2 + \frac{2\cos\theta\sin\theta}{4f} xy + \frac{\sin^2\theta}{4f} y^2 \\
	+ \left(\sin\theta - \frac{2h \cos\theta}{4f}\right)x + \left(\cos\theta - \frac{2h \sin\theta}{4f}\right)y + \frac{h^2}{4f} + k = 0
\end{multline*}
\begin{align}
	A &= \frac{\cos^2\theta}{4f} \\
	B &= \frac{2\cos\theta\sin\theta}{4f} \\
	C &= \frac{\sin^2\theta}{4f} \\
	D &= \sin\theta - \frac{2h \cos\theta}{4f} \\
	E &= \cos\theta - \frac{2h \sin\theta}{4f} \\
	F &= \frac{h^2}{4f} + k
\end{align}

\subsubsection{Hyperbolic Surface}
\begin{equation}
\begin{split}
	\frac{(\cos\theta(x-h) + \sin\theta(y-k))^2}{a^2} - \frac{(\cos\theta(y-k) + \sin\theta(x-h))^2}{b^2} &= 1 \\
	\frac{(x_c + y_s)^2}{a^2} - \frac{(y_c + x_s)^2}{b^2} &= 1 \\
	b^2(x_c^2 + 2x_c y_s + y_s^2) - a^2(y_c^2 + 2 x_s y_c + x_s^2) &= a^2 b^2 \\
	b^2 x_c^2 + 2 b^2 x_c y_s + b^2 y_s^2 - a^2 y_c^2 - 2 a^2 x_s y_c - a^2 x_s^2 - a^2 b^2 &= 0 \\
	b^2 x_c^2 - a^2 x_s^2 + 2 b^2 x_c y_s - 2 a^2 x_s y_c + b^2 y_s^2 - a^2 y_c^2 - a^2 b^2 &= 0 \\
\end{split}
\end{equation}
\begin{multline*}
	b^2 (\cos\theta(x-h))^2 - a^2 (\sin\theta(x-h))^2 \\
	+ 2 b^2 \cos\theta(x-h) \sin\theta(y-k) - 2 a^2 \sin\theta(x-h) \cos\theta(y-k) \\
	+ b^2 (\sin\theta(y-k))^2 - a^2 (\cos\theta(y-k))^2 - a^2 b^2 = 0
\end{multline*}
\begin{multline*}
	(b^2 \cos^2\theta - a^2 \sin^2\theta)(x-h)^2 \\
	+ 2 \cos\theta\sin\theta(b^2 - a^2)(x-h)(y-k) \\
	+ (b^2 \sin^2\theta - a^2 \cos^2\theta)(y-k)^2 - a^2 b^2 = 0
\end{multline*}
\begin{equation*}
	\begin{split}
		c_1(x-h)^2 + c_2(x-h)(y-k) + c_3(y-k)^2 - a^2 b^2 &= 0 \\
		c_1(x^2-2hx + h^2) + c_2(xy-hy-kx+hk) + c_3(y^2-2ky+k^2) - a^2 b^2 &= 0 \\
		c_1 x^2 + c_2 xy + c_3 y^2 + (-2h c_1 -k c_2) x + (-h c_2 -2k c_3)y + c_1 h^2 + c_2 hk + c_3 k^2 - a^2 b^2 &= 0 \\
	\end{split}
\end{equation*}
\begin{align*}
	A &= c_1 = b^2 \cos^2\theta - a^2 \sin^2\theta \\
	B &= c_2 = 2 \cos\theta\sin\theta(b^2 - a^2) \\
	C &= c_3 = b^2 \sin^2\theta - a^2 \cos^2\theta \\
	D &= (-2h c_1 -k c_2) \\
	E &= (-h c_2 -2k c_3) \\
	F &= c_1 h^2 + c_2 hk + c_3 k^2 - a^2 b^2
\end{align*}
Now to solve for $a$, $b$, and $\theta$:
Solving $A$ for $b^2$:
\begin{equation}
	\begin{split}
		A &= b^2 \cos^2\theta - a^2 \sin^2\theta \\
		b^2 &= \frac{A}{\cos^2\theta} + a^2\tan^2\theta \\
	\end{split}
\end{equation}
Setting 3.6 into $C$ and solving for $a^2$:
\begin{equation}
	\begin{split}
		C &= b^2 \sin^2\theta - a^2 \cos^2\theta \\
		a^2 &= -\frac{C}{\cos^2\theta} + b^2\tan^2\theta \\
		a^2 &= -\frac{C}{\cos^2\theta} + \left(\frac{A}{\cos^2\theta} + a^2\tan^2\theta\right)\tan^2\theta \\
		\cos^4\theta a^2 &= -C\cos^2\theta + A\cos^2\theta + \sin^4\theta a^2 \\
		(\cos^4\theta - \sin^4\theta) a^2  &= \cos^2\theta(A-C) \\
		a^2  &= \frac{\cos^2\theta(A-C)}{(\cos^4\theta - \sin^4\theta)} \\
	\end{split}
\end{equation}
Setting 3.6 into $B$:
\begin{equation}
	\begin{split}
		B &= 2 \cos\theta\sin\theta(\frac{A}{\cos^2\theta} + a^2\tan^2\theta - a^2) \\
		\cos^2\theta B &= 2 \cos\theta\sin\theta(A + (\sin^2\theta - \cos^2\theta) a^2) \\
	\end{split}
\end{equation}
Setting 3.7 into 3.8:
\begin{equation}
	\begin{split}
		\cos^2\theta B &= 2 \cos\theta\sin\theta(A + (\sin^2\theta - \cos^2\theta) \frac{\cos^2\theta(A-C)}{(\cos^4\theta - \sin^4\theta)}) \\
	\end{split}
\end{equation}

\section{Ramer-Douglas-Peucker Algorithm}
The Ramer-Douglas-Peucker (RDP) algorithm is a method to interatively simplify a line defined by a set of points\cite{RDP_line_reduction_DP, RDP_line_reduction_R}.
The only arguments to RDP are a list of points and a tolerance width, within which points will be considered unnecessary and discarded.
% The algorithm looks at a list of points, draws an imaginary line from the first to the last, finds the point with the farthest normal distance to the comparison line, and if the point's distance to the comparison line is greater than a pre-defined tolerance width, splits the lin
The algorithm iteratively finds the point farthest from the straight line from point 0 to n-1, and if said distance is greater than the tolerance width, the line is split at the farthest point and the line sections before and after the split are reconsidered individually.
The procedure is described in greater detail in algorithm \ref{alg:RDP}.

\begin{algorithm}[H]
\caption{Ramer-Douglas-Peucker}\label{alg:RDP}
\begin{algorithmic}[1]
\Function{SimplifyLineRDP}{points $P$, real $w$}
	\State new list $P_{core}$\Comment{To store the important point indices}
	\State new RDPNode $n_0 \leftarrow$ RDPNode($P$.first, $P$.last)
	\State new list $N_{stack} \leftarrow n_0$
	\While{$N_{stack}$ not empty}
		\State new RDPNode $n \leftarrow N_{stack}$.last
		\State $N_{stack}$.popLast()
		\State new uint $i \leftarrow$ index of point farthest from $n$.line
		\State new real $d \leftarrow$ distance of $P$[$i$] from $n$.line
		\If{$d \le w$} \Comment{If farthest point is within tolerance}
			\State $P_{core}$.append($n$.srcPt) \Comment{line section is complete}
			\State \textbf{continue}
		\EndIf
		\State new RDPNode $n_{left} \leftarrow$ RDPNode($n$.srcPt, $P$[$i$])
		\State new RDPNode $n_{right} \leftarrow$ RDPNode($P$[$i$], $n$.endPt)
		\State $N_{stack}$.append($n_{right}$)
		\State $N_{stack}$.append($n_{left}$)
	\EndWhile
	\State $P_{core}$.append($P$.last)
	\State \textbf{return} $P_{core}$
\EndFunction
\end{algorithmic}
\end{algorithm}

The RDP implementation used in this work uses a struct \textbf{RDPNode} that represents a section of the line.
It contains a start and end point, as well as a line spanning these two points.
A stack is used to manage the \textbf{RDPNode}s.
In each iteration of the \verb|while| loop, starting on line 5, the item at the top of the stack is removed and stored in $n$.
The point farthest from this line section is found, and on line 10 the distance thereof is compared against the tolerance width.
If the perpendicular distance is within the tolerance width then the current line section is complete and the initial point in the section is added to $P_{core}$ (line 11).
If not, then the current line section is split at the farthest point, with the two new sections represented by RDPNodes $n_{left}$ and $n_{right}$.
These are then placed on the stack, $n_{right}$ first, so that $n_{left}$ is processed next, ensuring the list of important points $P_{core}$ is always sorted.
After the \textbf{RDPNode} stack is exhausted the last point in $P$ is appended to $P_{core}$ because only the start point in each node is added to $P_{core}$.
An alternative implementation that uses recursion may be found on wikipedia.

\section{Traveling Salesman Problem}
The Traveling Salesman Problem (TSP) is a well known problem in combinatorial optimization.
The original problem was posed as the following:
A salesman wishes to visit every city in a given region once, to spend the least amount of time traveling between cities, and to end at his home city.
It was initially formulated in the 1800s by mathematicians William Rowan Hamilton and Thomas Kirkman\cite{Graph_theory}.
The problem can be stripped down to simply the optimal round-trip traversal of a set of nodes in a graph, where the traversal represents the salesman's movement, and each node represents a city.
It can be shown\cite{TSP_in_pursuit_of} that for $n$ nodes the number of possible route permutations is
\begin{equation*}
	n_{\text{routes}} = (n-1)!.
\end{equation*}
For the vast majority of applications symmetric node-to-node costs can be assumed, and the number of permutations is reduced to \textit{only}
\begin{equation*}
	n_{\text{routes}} = \frac{(n-1)!}{2}.
\end{equation*}
The number of real world TSP applications is similarly large\cite{TSP_theory_applications}, ranging from determining the drill order of holes in printed circuit board manufacturing\cite{TSP_PCB_manufacturing}, to mail delivery and vehicle routing in general\cite{TSP_mail_delivery}, to X-ray crystallography\cite{TSP_xray_crystallography}.
The algorithm described in this work produces a set of convex surfaces from the target object.
Within each convex surface region a simple path is planned.
% NOTE the verb tense/case! "would" because it is not implemented
It is the traversal of these surface regions that would be formulated as a TSP with the distance between each region and the change in end-effector orientation serving as the travel costs.
Considering only the traversal of the surface regions, the start and end nodes need not be the same, and the situation can be modeled as a modified TSP.
The common way to modify a TSP to achieve different start and end nodes is to introduce a dummy node with 0-cost edges to the other nodes\cite{TSP_dummy_node_mod}.
After insertion of the dummy node, the TSP can be solved like normal.
Once the TSP has been solved the nodes adjacent to the dummy node are the start and end nodes.
If the robot's starting or home position is included as a node, the application can be handled as a classic TSP.

